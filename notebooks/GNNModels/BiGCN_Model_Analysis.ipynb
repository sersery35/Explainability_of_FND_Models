{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "helper file to handle Bi-GCN model implementation in https://github.com/safe-graph/GNN-FakeNews\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from utils.gnn_utils.helpers import GNNModelTypeEnum\n",
    "from notebooks.utils import run_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from directory: /home/sersery/Desktop/TUM Informatik/SS22/Thesis/Code/Explainability_of_FND_Models/data\n",
      "\n",
      "************** epoch: 0 **************\n",
      "loss_train: 0.7070, acc_train: 0.2581,\n",
      "recall_train: 0.3077, auc_train: 0.1848,\n",
      "loss_val: 0.9045, acc_val: 0.4194,\n",
      "recall_val: 0.0000, auc_val: 0.3974\n",
      "***************************************\n",
      "\n",
      "************** epoch: 1 **************\n",
      "loss_train: 0.7197, acc_train: 0.5806,\n",
      "recall_train: 0.0000, auc_train: 0.4925,\n",
      "loss_val: 0.6769, acc_val: 0.5806,\n",
      "recall_val: 0.4444, auc_val: 0.7265\n",
      "***************************************\n",
      "\n",
      "************** epoch: 2 **************\n",
      "loss_train: 0.6324, acc_train: 0.7742,\n",
      "recall_train: 0.5000, auc_train: 0.8323,\n",
      "loss_val: 0.6166, acc_val: 0.6774,\n",
      "recall_val: 0.8889, auc_val: 0.7607\n",
      "***************************************\n",
      "\n",
      "************** epoch: 3 **************\n",
      "loss_train: 0.6304, acc_train: 0.6613,\n",
      "recall_train: 0.9615, auc_train: 0.8291,\n",
      "loss_val: 0.6163, acc_val: 0.6774,\n",
      "recall_val: 0.8333, auc_val: 0.7393\n",
      "***************************************\n",
      "\n",
      "************** epoch: 4 **************\n",
      "loss_train: 0.5941, acc_train: 0.7258,\n",
      "recall_train: 0.8846, auc_train: 0.8323,\n",
      "loss_val: 0.6461, acc_val: 0.6774,\n",
      "recall_val: 0.5556, auc_val: 0.7564\n",
      "***************************************\n",
      "\n",
      "************** epoch: 5 **************\n",
      "loss_train: 0.5615, acc_train: 0.7581,\n",
      "recall_train: 0.5000, auc_train: 0.8301,\n",
      "loss_val: 0.7153, acc_val: 0.5161,\n",
      "recall_val: 0.2222, auc_val: 0.7436\n",
      "***************************************\n",
      "\n",
      "************** epoch: 6 **************\n",
      "loss_train: 0.5519, acc_train: 0.7419,\n",
      "recall_train: 0.4231, auc_train: 0.8590,\n",
      "loss_val: 0.6850, acc_val: 0.5161,\n",
      "recall_val: 0.2778, auc_val: 0.7350\n",
      "***************************************\n",
      "\n",
      "************** epoch: 7 **************\n",
      "loss_train: 0.5271, acc_train: 0.7581,\n",
      "recall_train: 0.4615, auc_train: 0.8750,\n",
      "loss_val: 0.6243, acc_val: 0.7742,\n",
      "recall_val: 0.7778, auc_val: 0.7350\n",
      "***************************************\n",
      "\n",
      "************** epoch: 8 **************\n",
      "loss_train: 0.4984, acc_train: 0.8387,\n",
      "recall_train: 0.6538, auc_train: 0.8857,\n",
      "loss_val: 0.5750, acc_val: 0.7742,\n",
      "recall_val: 0.8333, auc_val: 0.7778\n",
      "***************************************\n",
      "\n",
      "************** epoch: 9 **************\n",
      "loss_train: 0.4842, acc_train: 0.8387,\n",
      "recall_train: 0.8077, auc_train: 0.8846,\n",
      "loss_val: 0.5705, acc_val: 0.7742,\n",
      "recall_val: 0.8333, auc_val: 0.7521\n",
      "***************************************\n",
      "\n",
      "************** epoch: 10 **************\n",
      "loss_train: 0.4692, acc_train: 0.8226,\n",
      "recall_train: 0.7692, auc_train: 0.8825,\n",
      "loss_val: 0.6519, acc_val: 0.7742,\n",
      "recall_val: 0.7778, auc_val: 0.7265\n",
      "***************************************\n",
      "\n",
      "************** epoch: 11 **************\n",
      "loss_train: 0.4360, acc_train: 0.8387,\n",
      "recall_train: 0.6923, auc_train: 0.8878,\n",
      "loss_val: 0.6620, acc_val: 0.6774,\n",
      "recall_val: 0.5556, auc_val: 0.7607\n",
      "***************************************\n",
      "\n",
      "************** epoch: 12 **************\n",
      "loss_train: 0.4333, acc_train: 0.8387,\n",
      "recall_train: 0.6538, auc_train: 0.8974,\n",
      "loss_val: 0.6064, acc_val: 0.8065,\n",
      "recall_val: 0.7778, auc_val: 0.7735\n",
      "***************************************\n",
      "\n",
      "************** epoch: 13 **************\n",
      "loss_train: 0.4039, acc_train: 0.8387,\n",
      "recall_train: 0.6923, auc_train: 0.9124,\n",
      "loss_val: 0.5712, acc_val: 0.8065,\n",
      "recall_val: 0.7778, auc_val: 0.7650\n",
      "***************************************\n",
      "\n",
      "************** epoch: 14 **************\n",
      "loss_train: 0.3774, acc_train: 0.8387,\n",
      "recall_train: 0.7692, auc_train: 0.9209,\n",
      "loss_val: 0.6557, acc_val: 0.8065,\n",
      "recall_val: 0.8333, auc_val: 0.7821\n",
      "***************************************\n",
      "Test set results: acc: 0.7738, f1_macro: 0.7720, f1_micro: 0.7738,precision: 0.7520, recall: 0.8345, auc: 0.8641, ap: 0.8407\n"
     ]
    }
   ],
   "source": [
    "model = run_model(GNNModelTypeEnum.BIGCN, test_mode=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 training samples are fetched.\n",
      "10 test samples are fetched.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BiGCNet.forward() takes 2 positional arguments but 31 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/TUM Informatik/SS22/Thesis/Code/Explainability_of_FND_Models/utils/gnn_utils/helpers.py:125\u001B[0m, in \u001B[0;36mGNNModelHelper.explain\u001B[0;34m(self, background_data, test_data)\u001B[0m\n\u001B[1;32m    123\u001B[0m background \u001B[38;5;241m=\u001B[39m background_data \u001B[38;5;28;01mif\u001B[39;00m background_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm_dataset_manager\u001B[38;5;241m.\u001B[39mget_train_samples()\n\u001B[1;32m    124\u001B[0m test \u001B[38;5;241m=\u001B[39m test_data \u001B[38;5;28;01mif\u001B[39;00m test_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm_dataset_manager\u001B[38;5;241m.\u001B[39mget_test_samples()\n\u001B[0;32m--> 125\u001B[0m explainer \u001B[38;5;241m=\u001B[39m \u001B[43mshap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDeepExplainer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackground\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    126\u001B[0m shap_values \u001B[38;5;241m=\u001B[39m explainer\u001B[38;5;241m.\u001B[39mshap_values(test)\n\u001B[1;32m    127\u001B[0m shap\u001B[38;5;241m.\u001B[39mimage_plot(shap_values, test)\n",
      "File \u001B[0;32m~/anaconda3/envs/thesis/lib/python3.10/site-packages/shap/explainers/_deep/__init__.py:86\u001B[0m, in \u001B[0;36mDeep.__init__\u001B[0;34m(self, model, data, session, learning_phase_flags)\u001B[0m\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplainer \u001B[38;5;241m=\u001B[39m TFDeep(model, data, session, learning_phase_flags)\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m framework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpytorch\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplainer \u001B[38;5;241m=\u001B[39m \u001B[43mPyTorchDeep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexpected_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplainer\u001B[38;5;241m.\u001B[39mexpected_value\n",
      "File \u001B[0;32m~/anaconda3/envs/thesis/lib/python3.10/site-packages/shap/explainers/_deep/deep_pytorch.py:54\u001B[0m, in \u001B[0;36mPyTorchDeep.__init__\u001B[0;34m(self, model, data)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 54\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;66;03m# also get the device everything is running on\u001B[39;00m\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mdevice\n",
      "File \u001B[0;32m~/anaconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[0;31mTypeError\u001B[0m: BiGCNet.forward() takes 2 positional arguments but 31 were given"
     ]
    }
   ],
   "source": [
    "model.explain()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}